# -*- coding: utf-8 -*-
"""Task for Multilabel (Github).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BiVmVtiPyCI1rBGROvlMzHez3gEjyzvD

# **Section：Data Cleaning**

## **Step1** : Setup and load data

In this step, I load the excel dataset and the tool we need to use.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import classification_report, accuracy_score, hamming_loss
from collections import Counter

df = pd.read_excel('/content/Studiendaten für Similarity analyse neu.xlsx')

df.shape

"""## **Step2** : Drop unnecessary variable

I deleted some obviously duplicate or invalid features based on the meaning of the feature and the information it contained.

| Feature     | What it is        | Why drop it     |
|--------------|-----------------|--------------|
| 1. Eingangsbuchnummer| Unique entry number for each patient.| It carries no clinical information|
| 2. Geburtsdatum | Patient’s date of birth | Redundant once you have “Alter des Patienten bei Diagnose(Age in years at initial cancer diagnosis).” |
| 3. OP Datum| Date of primary tumor surgery.| The raw surgery date isn’t needed if using PFS/OS instead. |
| 4. Progress| Text flag indicating whether a tumor progression was recorded.| A text flag (“ja”/“nein”) that’s fully captured by the PFS variable. |
| 5. Progress Datum| Date when tumor progression was documented. | Progression date is covered by PFS, so not needed separately.|
| 6. Nachsorge Datum | Date of last follow-up visit.| This data is not useful when we already have PFS/OS |
| 7. Todesdatum |  Date of death. | Covered by the OS |
| 8. Anzahl Metastasen extrahepatisch |  Number of metastases outside the liver. | whole column NA |
"""

# list of columns to remove
cols_to_drop = [
    'Eingangsbuchnummer',
    'Geburtsdatum',
    'OP Datum',
    'Progress',
    'Progress Datum',
    'Nachsorge Datum',
    'Todesdatum']

# create a new DataFrame without those columns
df = df.drop(columns=cols_to_drop)

# verify
print(df.shape)



"""## **Step3** : Data types convert

Since all the data types read are object, it is necessary to make a basic correction to the data type first.
"""

df.dtypes

"""Convert some feature back to numeric type"""

# Convert to numeric type
to_numeric_cols = [
    'Alter des Patienten bei Diagnose',
    'PFS',
    'OS',
    'BMI',
    'Tumor/Metastasen Durchmesser'
]

for col in to_numeric_cols:
    if col in df.columns:

        s = df[col].astype(str).str.replace(',', '.').str.strip()
        # set the unparsed ones to NaN
        df[col] = pd.to_numeric(s, errors='coerce')

# Check results
print(df[to_numeric_cols].dtypes)

"""Convert some features back to category"""

def convert_to_category(df, threshold=0.05, max_unique=50):
    n = len(df)
    for col in df.select_dtypes(include=['object']).columns:
        nunique = df[col].nunique(dropna=False)
        ratio = nunique / n
        if nunique <= max_unique and ratio <= threshold:
            df[col] = df[col].astype('category')
    return df

df = convert_to_category(df)

"""For subsequent calculations, these four features are also converted into categorical types."""

cat_cols = [
    "Hauptdiagnose PT",
    "Wirkstoffschema neoadjuvante Therapie",
    "Wirkstoffschema adjuvante Therapie",
    "Wirkstoffschema der Adjuvanten Therapie des Primärtumors oder vorhergegangener Metastase"
]

for col in cat_cols:
    df[col] = df[col].astype("category")

"""Final Check the data type"""

df.info()

"""### boxplots for numeric features after type conversion"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=df[to_numeric_cols])
plt.title('Boxplots of Numeric Features (Post-Type Conversion)')
plt.xticks(rotation=45)
plt.savefig('post_type_boxplots.png')  # Save for PPT
plt.show()

"""## **Step4** : Handling outliers

### Count the number of outliers and find their indices
"""

# 1. Identify your numeric columns (adjust as needed)
num_cols = df.select_dtypes(include='number').columns

# 2. Loop through and collect outlier info
for col in num_cols:
    # Compute Q1, Q3 and IQR
    Q1, Q3 = df[col].quantile([0.25, 0.75])
    IQR = Q3 - Q1
    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR

    # Build a Boolean mask of outliers
    mask = (df[col] < lower) | (df[col] > upper)

    # Extract the indices where mask is True
    outlier_idxs = df.index[mask].tolist()

    # Print summary
    print(f"{col!r}: {len(outlier_idxs)} outliers")
    print(f"  Indices: {outlier_idxs}\n")

"""### Outlier handling

Replace outlier with upper or lower IQR bounds
"""

custom_bounds = {
    'BMI': (10.0, 60.0),
    'Tumor/Metastasen Durchmesser': (0.1, 30.0)
    # Add more if needed, e.g., 'Alter des Patienten bei Diagnose': (0, 120),
    # 'PFS': (0, None),  # None for no upper cap
    # 'OS': (0, None)
}

# Cap each numeric column
for col in num_cols:
    if col in custom_bounds:
        lower, upper = custom_bounds[col]
        # If upper is None, don't cap upper
        if upper is None:
            df[col] = df[col].clip(lower=lower)
        elif lower is None:
            df[col] = df[col].clip(upper=upper)
        else:
            df[col] = df[col].clip(lower=lower, upper=upper)
        print(f"Capped {col} to custom bounds: [{lower}, {upper}]")
    else:
        # Fallback to IQR
        Q1, Q3 = df[col].quantile([0.25, 0.75])
        IQR = Q3 - Q1
        lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower, upper=upper)
        print(f"Capped {col} to IQR bounds: [{lower}, {upper}]")

"""### boxplots after outlier handling for comparison"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=df[num_cols])
plt.title('Boxplots of Numeric Features (Post-Outlier Handling)')
plt.xticks(rotation=45)
plt.savefig('post_outlier_boxplots.png')  # Save for PPT
plt.show()

"""## **Step5** : Missing value imputation

### Count missing value
"""

# replace the missing_markers (empty) to NA
missing_markers = ['']
df.replace(missing_markers, pd.NA, inplace=True)

# Check
print(df.isna().sum())

"""### Change the missing markers

Alter des Patienten bei Diagnose
: fehlt to NA

PFS
: fehlt to NA

OS
: fehlt to NA, keine Angabe to NA

BMI
: fehlt to NA, keine Angabe to NA

V-Status
: keine Angabe to k.A.

L-Status
: keine Angabe to k.A.

Tumor/Metastasen Durchmesser
: fehlt to NA, k.A. to NA
"""

replacements = {
    'Alter des Patienten bei Diagnose':           {'fehlt': pd.NA},
    'PFS':                                        {'fehlt': pd.NA},
    'OS':                                         {'fehlt': pd.NA, 'keine Angabe': pd.NA},
    'BMI':                                        {'fehlt': pd.NA, 'keine Angabe': pd.NA},
    'Tumor/Metastasen Durchmesser':               {'fehlt': pd.NA, 'k.A.': pd.NA},
}

# 2. Replacement (inplace=True will modify df directly)
df.replace(replacements, inplace=True)

# 3. Check the result
print(df[['Alter des Patienten bei Diagnose','PFS','OS','BMI',
          'Tumor/Metastasen Durchmesser']].isna().sum())

"""### Convert all string entries to lowercase"""

# 1. Lowercase all object-dtype (pure string) columns
obj_cols = df.select_dtypes(include='object').columns
df[obj_cols] = df[obj_cols].apply(lambda s: s.str.lower())

# 2. For each categorical column, convert to string, lowercase, then recast to category
cat_cols = df.select_dtypes(include='category').columns
for col in cat_cols:
    df[col] = (
        df[col]
          .astype('string')
          .str.lower()
          .astype('category')
    )

df.head()

"""### The NA Chart"""

import matplotlib.pyplot as plt

# 1. Count NaNs per column
nan_counts = df.isna().sum()

# 2. Plot horizontal bar chart
plt.figure(figsize=(10, 8))
plt.barh(nan_counts.index, nan_counts.values)
plt.xlabel('Number of missing values')
plt.title('Distribution of Missing Values per Feature')
plt.tight_layout()
plt.show()

"""### Imputation (Numeric with KNN, Category with mode)"""

from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler

num_cols = df.select_dtypes(include=['number']).columns

# Scale all features equally
scaler = StandardScaler()
X_num_scaled = scaler.fit_transform(df[num_cols])

# Create and fit the KNN imputer
imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')
X_num_imputed_scaled = imputer.fit_transform(X_num_scaled)

# Inverse-transform to get back to original scale
X_num_imputed = scaler.inverse_transform(X_num_imputed_scaled)
df[num_cols] = X_num_imputed

# Categorical columns, fill with mode
cat_cols = df.select_dtypes(include=['object', 'category']).columns
for col in cat_cols:
    if df[col].isna().any():
        df[col].fillna(df[col].mode()[0], inplace=True)

# Verify
print("Missing values after KNN imputation:")
print(df.isna().sum())

"""### Histograms after imputation for comparison"""

plt.figure(figsize=(12, 8))
for i, col in enumerate(num_cols, 1):  # Use num_cols instead of num_cols_pre
    plt.subplot(2, 3, i)
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col} (Post-Imputation)')
plt.tight_layout()
plt.savefig('post_imputation_distributions.png')  # Save for PPT
plt.show()

df_clean_org = df.copy()

# Assume the two labels are in columns 'label1' and 'label2'

feature_cols = [c for c in df_clean_org.columns if c not in ["Wirkstoffschema adjuvante Therapie", "Wirkstoffschema neoadjuvante Therapie"]]
X = df_clean_org[feature_cols]
y = df_clean_org[["Wirkstoffschema adjuvante Therapie", "Wirkstoffschema neoadjuvante Therapie"]]

"""### Class distribution bar charts for multilabel targets"""

fig, axes = plt.subplots(1, 2, figsize=(14, 6))
sns.countplot(x=y.iloc[:, 0], ax=axes[0])
axes[0].set_title('Class Distribution: Wirkstoffschema neoadjuvante Therapie')
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90)
sns.countplot(x=y.iloc[:, 1], ax=axes[1])
axes[1].set_title('Class Distribution: Wirkstoffschema adjuvante Therapie')
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90)
plt.tight_layout()
plt.savefig('class_distributions.png')  # Save for PPT
plt.show()

"""## **Step6** : Correlation

### Convert all category type to numeirc

1. Identifies all categorical columns based on data types.  
2. Manually defines ordinal columns (e.g., medical stages like 'T‑Status') with custom ordering to preserve logical hierarchy.  
3. Auto‑detects binary columns (excluding ordinals) for efficient label encoding.  
4. Separates nominal columns (multi‑category, non‑ordinal) for one‑hot encoding to avoid implying order.  
5. Treats the target column ('Wirkstoffschema neoadjuvante Therapie') separately with label encoding.
"""

# Identify categorical columns
categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
unique_counts = df[categorical_cols].nunique()

# Define ordinal columns manually (note: 'Grading ' has trailing space)
ordinal_cols = ['T-Status', 'N-Status', 'M-Status', 'V-Status', 'L-Status', 'Pn-Status', 'Grading ']

# Custom orders for ordinals
ordinal_orders = {
    'T-Status': ['tis', 'pt1', 't1', 'pt2', 't2', 'ct2', 'pt3', 't3', 'ct3', 'pt4', 't4', 'ct4', 'keine angabe'],
    'N-Status': ['pn0', 'n0', 'cn0', 'pn1', 'n1', 'cn1', 'pn2', 'n2', 'cn2', 'keine angabe'],
    'M-Status': ['m0', 'cm0', 'pm0', 'm1', 'cm1', 'pm1', 'keine angabe'],
    'V-Status': ['v0', 'v1', 'fehlt', 'keine angabe'],
    'L-Status': ['l0', 'l1', 'fehlt', 'keine angabe'],
    'Pn-Status': ['pn0', 'pn1', 'k.a.', 'fehlt'],
    'Grading ': ['g1', 'g2', 'g3', 'g4', 'keine angabe']
}

# Binary: auto-detect ==2 uniques
binary_cols = [col for col in categorical_cols if unique_counts[col] == 2 and col not in ordinal_cols]

# Nominal: the rest (>2 uniques, not ordinal)
nominal_cols = [col for col in categorical_cols if col not in ordinal_cols and col not in binary_cols]

# Targets: treat separately (label encode) and save encoders
target_col = 'Wirkstoffschema neoadjuvante Therapie'
target_post = 'Wirkstoffschema adjuvante Therapie'
if target_col in nominal_cols:
    nominal_cols.remove(target_col)
if target_post in nominal_cols:
    nominal_cols.remove(target_post)

# Print for verification
print("Binary (label):", binary_cols)
print("Ordinal (ordinal encode):", ordinal_cols)
print("Nominal (one-hot):", nominal_cols)
print("Targets (label):", target_col, target_post)

# Label encode binary
le = LabelEncoder()
for col in binary_cols:
    df[col] = le.fit_transform(df[col].astype(str))

# Ordinal encode with custom categories
for col, order in ordinal_orders.items():
    oe = OrdinalEncoder(categories=[order], handle_unknown='use_encoded_value', unknown_value=-1)
    df[col] = oe.fit_transform(df[[col]].astype(str))



# One-hot nominal (with drop_first to avoid multicollinearity)
df = pd.get_dummies(df, columns=nominal_cols, drop_first=True)

# Label encode targets and save encoders
le_target = LabelEncoder()
df[target_col] = le_target.fit_transform(df[target_col].astype(str))

le_post = LabelEncoder()
df[target_post] = le_post.fit_transform(df[target_post].astype(str))

# Inspect
print("Encoded shape:", df.shape)
print(df.dtypes)

"""### Correlation Matrix and heatmap"""

# Calculate correlation matrix
corr_matrix = df.corr()
print("Correlation Matrix:\n", corr_matrix)

# Correlations with target
if target_col in corr_matrix.columns:
    target_corr = corr_matrix[target_col].sort_values(ascending=False)
    print("\nCorrelations with Target:\n", target_corr)

# High correlation pairs (|corr| > 0.5, excluding self)
high_corr = corr_matrix.abs().where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)).unstack().dropna().sort_values(ascending=False)
high_corr_pairs = high_corr[high_corr > 0.5]
print("\nHigh Correlation Pairs (>0.5):\n", high_corr_pairs)

# Visualize heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""### Find the Best Threshold Value and Removing Correlated Features"""

# Separate features and targets (drop BOTH targets for correlation among features only)
X = df.drop(columns=[target_col, target_post])
y = df[[target_col, target_post]]  # Multilabel targets

# Absolute correlation matrix (on features only)
corr_matrix = X.corr().abs()

# Function to select features below threshold
def select_features(corr_matrix, threshold):
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]
    return [col for col in X.columns if col not in to_drop]

# Evaluate performance for a given threshold
def evaluate_threshold(threshold):
    selected_features = select_features(corr_matrix, threshold)
    if len(selected_features) == 0:
        return 0, []
    X_selected = X[selected_features]
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    scores = cross_val_score(model, X_selected, y.iloc[:, 0], cv=5, scoring='accuracy')  # Use one target for quick eval
    return scores.mean(), selected_features

# Test thresholds from 0.5 to 0.95
thresholds = np.arange(0.5, 1.0, 0.05)
results = {}
best_threshold = None
best_score = -1
best_features = []

for thresh in thresholds:
    score, features = evaluate_threshold(thresh)
    results[thresh] = (score, len(features))
    if score > best_score and len(features) > 0:
        best_score = score
        best_threshold = thresh
        best_features = features

# Find optimal: minimize features while score within 5% of max
max_score = max([s[0] for s in results.values()])
optimal_threshold = max([t for t, (s, f) in results.items() if s >= max_score * 0.95], key=lambda t: results[t][1], default=best_threshold)

print(f"Best Threshold: {optimal_threshold}")
print(f"Features after removal: {best_features}")

# Create cleaned DataFrame with selected features + targets
df_clean = df[best_features + [target_col, target_post]].copy()

"""# **Classification Algorithms**

**Multilabel Classification**
"""

# --- Multilabel Classification using MultiOutputClassifier ---
from sklearn.metrics import classification_report, accuracy_score, hamming_loss
from collections import Counter
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


# Features and targets (both already numeric from encoding)
X = df_clean.drop(columns=[target_col, target_post])
y = df_clean[[target_col, target_post]]

# Handle rare classes: filter combinations with >=2 samples for stratification
y_combined = y[target_col].astype(str) + '_' + y[target_post].astype(str)
class_counts = Counter(y_combined)
valid_classes = [cls for cls, count in class_counts.items() if count >= 2]
mask = np.isin(y_combined, valid_classes)
dropped_count = len(y) - mask.sum()
print(f"Dropped {dropped_count} samples due to rare class combinations (<2 samples).")

X_filtered = X[mask]
y_filtered = y[mask]
y_combined_filtered = y_combined[mask].values  # Convert to NumPy array here

# Train/test split with stratification on combined labels
X_train, X_test, y_train, y_test = train_test_split(
    X_filtered, y_filtered,
    test_size=0.2,
    random_state=42,
    stratify=y_combined_filtered
)

# Feature scaling (optional for RandomForest, but included for completeness)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Base classifier with balanced class weights
base_clf = RandomForestClassifier(
    n_estimators=100,
    class_weight='balanced_subsample',
    random_state=42
)

# MultiOutputClassifier
multi_clf = MultiOutputClassifier(base_clf)
multi_clf.fit(X_train_scaled, y_train)

# Predict
y_pred = multi_clf.predict(X_test_scaled)  # This is a NumPy array (n_samples, 2)

# Evaluate - Manual subset accuracy (exact match across both labels)
subset_acc = (y_test.values == y_pred).all(axis=1).mean()
print(f"Subset accuracy (exact match for both labels): {subset_acc:.3f}")

# Manual Hamming loss (average fraction of mismatched labels)
h_loss = np.mean(y_test.values != y_pred)
print(f"Hamming loss: {h_loss:.3f}\n")


# Per-label reports (inverse transform to original labels using saved encoders)
y_test_neo_orig = le_target.inverse_transform(y_test[target_col])
y_pred_neo_orig = le_target.inverse_transform(y_pred[:, 0])  # First output is neoadjuvante

print("=== Report for Wirkstoffschema neoadjuvante Therapie ===")
print(classification_report(y_test_neo_orig, y_pred_neo_orig))

y_test_adj_orig = le_post.inverse_transform(y_test[target_post])
y_pred_adj_orig = le_post.inverse_transform(y_pred[:, 1])  # Second output is adjuvante

print("=== Report for Wirkstoffschema adjuvante Therapie ===")
print(classification_report(y_test_adj_orig, y_pred_adj_orig))

# Feature importance (average across both classifiers)
importances = np.mean([est.feature_importances_ for est in multi_clf.estimators_], axis=0)
feature_importance = pd.Series(importances, index=X.columns).nlargest(10)
print("Top 10 Important Features (averaged):\n", feature_importance)

# Bar plot for feature importance
plt.figure(figsize=(10, 6))
feature_importance.plot(kind='barh')
plt.title('Top 10 Feature Importances (Averaged Across Labels)')
plt.xlabel('Importance Score')
plt.savefig('feature_importance.png')  # Save for PPT
plt.show()

# Actual vs Predicted table
results = pd.DataFrame({
    'Actual Neoadjuvante': y_test_neo_orig,
    'Predicted Neoadjuvante': y_pred_neo_orig,
    'Actual Adjuvante': y_test_adj_orig,
    'Predicted Adjuvante': y_pred_adj_orig
})
results['Match Both'] = (results['Actual Neoadjuvante'] == results['Predicted Neoadjuvante']) & (results['Actual Adjuvante'] == results['Predicted Adjuvante'])

print("Actual vs Predicted Table (Sample 20 rows):\n", results.head(20))
results.to_csv('actual_vs_predicted_multilabel.csv', index=False)
print("Full table saved to 'actual_vs_predicted_multilabel.csv'")

# Display a table of actual vs predicted values
display(results.head(20))

# Confusion matrices for each label (fixed to handle all classes)
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

fig, axes = plt.subplots(1, 2, figsize=(20, 10))  # Increased size for many labels

# For neoadjuvante: Force full label set
cm_neo = confusion_matrix(y_test_neo_orig, y_pred_neo_orig, labels=le_target.classes_)
disp_neo = ConfusionMatrixDisplay(cm_neo, display_labels=le_target.classes_)
disp_neo.plot(ax=axes[0], cmap='Blues')
axes[0].set_title('CM: Neoadjuvante Therapie')
axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=90, ha='right', fontsize=8)
axes[0].set_yticklabels(axes[0].get_yticklabels(), rotation=0, fontsize=8)

# For adjuvante: Force full label set (assuming similar issue)
cm_adj = confusion_matrix(y_test_adj_orig, y_pred_adj_orig, labels=le_post.classes_)
disp_adj = ConfusionMatrixDisplay(cm_adj, display_labels=le_post.classes_)
disp_adj.plot(ax=axes[1], cmap='Blues')
axes[1].set_title('CM: Adjuvante Therapie')
axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=90, ha='right', fontsize=8)
axes[1].set_yticklabels(axes[1].get_yticklabels(), rotation=0, fontsize=8)

plt.tight_layout()
plt.savefig('confusion_matrices.png', dpi=300)  # Higher DPI for PPT clarity
plt.show()

"""## Feature Selection"""

## Feature Selection

# 1. Feature Importance (already computed in the model; re-extract for clarity)
importances = np.mean([est.feature_importances_ for est in multi_clf.estimators_], axis=0)
feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)
print("Feature Importances (Top 10):")
print(feature_importance.head(10))

# 2. Correlation Analysis (build on existing corr_matrix; drop >0.95 correlated)
corr_matrix = X.corr().abs()
upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]
print(f"Dropped {len(to_drop)} highly correlated features: {to_drop}")

X_dropped = X.drop(columns=to_drop)
X_train_dropped = scaler.fit_transform(X_train.drop(columns=to_drop))
X_test_dropped = scaler.transform(X_test.drop(columns=to_drop))


# 3. Recursive Feature Elimination (RFE) - Select top 10 features
from sklearn.feature_selection import RFE

rfe = RFE(estimator=base_clf, n_features_to_select=10, step=1)
rfe.fit(X_train_dropped, y_train.iloc[:, 0])  # Use first label for RFE approximation

selected_features = X_dropped.columns[rfe.support_]
print("\nTop 10 Features from RFE:")
print(selected_features)


# Evaluate model with top features
X_train_top = X_train_dropped[:, rfe.support_]
X_test_top = X_test_dropped[:, rfe.support_]

multi_clf_top = MultiOutputClassifier(base_clf)
multi_clf_top.fit(X_train_top, y_train)
y_pred_top = multi_clf_top.predict(X_test_top)

# Manual metrics
subset_acc_top = (y_test.values == y_pred_top).all(axis=1).mean()
h_loss_top = np.mean(y_test.values != y_pred_top)
print(f"\nPerformance with Top 10 Features: Subset Acc = {subset_acc_top:.3f}, Hamming Loss = {h_loss_top:.3f}")

# Compare to full (post-correlation)
multi_clf_full = MultiOutputClassifier(base_clf)
multi_clf_full.fit(X_train_dropped, y_train)
y_pred_full = multi_clf_full.predict(X_test_dropped)
subset_acc_full = (y_test.values == y_pred_full).all(axis=1).mean()
h_loss_full = np.mean(y_test.values != y_pred_full)
print(f"Performance with All Features (post-correlation): Subset Acc = {subset_acc_full:.3f}, Hamming Loss = {h_loss_full:.3f}")

"""## Hyperparameter Tuning"""

## Hyperparameter Tuning

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer # Import make_scorer

# Define parameter grid for RandomForest (base estimator)
param_grid = {
    'estimator__n_estimators': [50, 100, 200],
    'estimator__max_depth': [None, 10, 20],
    'estimator__min_samples_split': [2, 5, 10],
    'estimator__class_weight': ['balanced', None]
}

# MultiOutputClassifier with GridSearchCV
# Use subset accuracy as scorer (manual function for multilabel)
def subset_accuracy(y_true, y_pred):
    return np.mean(np.all(y_true == y_pred, axis=1))

scorer = make_scorer(subset_accuracy, greater_is_better=True)

grid_search = GridSearchCV(
    estimator=MultiOutputClassifier(RandomForestClassifier(random_state=42)),
    param_grid=param_grid,
    cv=5,
    scoring=scorer,
    n_jobs=-1,
    verbose=1
)

# Fit on training data (use post-feature-selection X if desired; here using full X_train_scaled)
grid_search.fit(X_train_scaled, y_train)

# Plot CV results from GridSearch for hyperparameter insights
cv_results = pd.DataFrame(grid_search.cv_results_)
plt.figure(figsize=(10, 6))
sns.lineplot(data=cv_results, x='param_estimator__n_estimators', y='mean_test_score', hue='param_estimator__max_depth')
plt.title('GridSearch CV Scores by n_estimators and max_depth')
plt.savefig('gridsearch_cv_scores.png')  # Save for PPT
plt.show()

# Best params and score
print("Best Hyperparameters:", grid_search.best_params_)
print("Best Cross-Validation Score (Subset Acc):", grid_search.best_score_)

# Re-train with best params
best_clf = grid_search.best_estimator_
best_clf.fit(X_train_scaled, y_train)

# Predict and evaluate on test
y_pred_best = best_clf.predict(X_test_scaled)

subset_acc_best = (y_test.values == y_pred_best).all(axis=1).mean()
h_loss_best = np.mean(y_test.values != y_pred_best)

print(f"Performance with Tuned Model: Subset Acc = {subset_acc_best:.3f}, Hamming Loss = {h_loss_best:.3f}")

# Compare to original
print(f"Original Performance: Subset Acc = {subset_acc:.3f}, Hamming Loss = {h_loss:.3f}")